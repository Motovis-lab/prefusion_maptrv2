{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import virtual_camera as vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, figsize=(16, 9)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_file = '../data/20230823_110018/mv_4d_infos.pkl'\n",
    "\n",
    "scenes = mmengine.load(info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = scenes['20230823_110018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'some information with this scene',\n",
       " 'space_range': {'map': [36, -12, -12, 12, 10, -10],\n",
       "  'det': [36, -12, -12, 12, 10, -10],\n",
       "  'occ': [36, -12, -12, 12, 10, -10]},\n",
       " 'time_range': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene['meta_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['scene_info', 'meta_info', 'frame_info']),\n",
       " dict_keys(['VCAMERA_FISHEYE_BACK', 'VCAMERA_FISHEYE_FRONT', 'VCAMERA_FISHEYE_LEFT', 'VCAMERA_FISHEYE_RIGHT', 'VCAMERA_PERSPECTIVE_BACK_LEFT', 'VCAMERA_PERSPECTIVE_BACK', 'VCAMERA_PERSPECTIVE_BACK_RIGHT', 'VCAMERA_PERSPECTIVE_FRONT_LEFT', 'VCAMERA_PERSPECTIVE_FRONT', 'VCAMERA_PERSPECTIVE_FRONT_RIGHT']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene.keys(), scene['scene_info']['camera_mask'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene['scene_info']['camera_mask']['VCAMERA_FISHEYE_FRONT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for scene_id in scenes:\n",
    "    for frame in scenes[scene_id]['frame_info']:\n",
    "        indices.append('/'.join([scene_id, frame]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen an Image transformable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.transform import Image, Bbox3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_type_from_sensor_name(sensor_name):\n",
    "    if 'perspective' in sensor_name.lower():\n",
    "        return 'PerspectiveCamera'\n",
    "    elif 'fisheye' in sensor_name.lower():\n",
    "        return 'FisheyeCamera'\n",
    "    else:\n",
    "        raise ValueError('Unknown camera type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = scene['scene_info']['calibration'].keys()\n",
    "\n",
    "for sensor in sensors:\n",
    "    print(sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(scene['frame_info'].keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sorted(scene['frame_info'].keys())\n",
    "ss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_frame(timestamp, sequence):\n",
    "    for t in sequence:\n",
    "        if int(timestamp) <= int(t):\n",
    "            return sequence.index(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = index_frame('1692759621555', ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_modes = [\n",
    "    dict(mode='INTERVAL',\n",
    "         args=dict(interval=1,\n",
    "                   nframes=3)),\n",
    "    dict(mode='SINGLE'),\n",
    "    dict(mode='SEQUENTIAL',\n",
    "         args=dict(duration=3))\n",
    "]\n",
    "\n",
    "sequence_modes[0]['mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = 'VCAMERA_PERSPECTIVE_FRONT'\n",
    "\n",
    "\n",
    "img_data = {\n",
    "    'cam_id': sensor_name,\n",
    "    'cam_type': get_cam_type_from_sensor_name(sensor_name)\n",
    "}\n",
    "img_data.update(scene['scene_info']['calibration'][sensor_name])\n",
    "img_data['img'] = mmcv.imread(data_root / scene['frame_info']['1692759619664']['camera_image'][sensor_name])\n",
    "img_data['ego_mask'] = mmcv.imread(data_root / scene['scene_info']['camera_mask'][sensor_name + '_MASK'], flag='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(32, 18))\n",
    "# imshow(img_data['img'][..., ::-1])\n",
    "# imshow(img_data['ego_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_front = Image(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_R = Rotation.from_euler('xyz', [0, 0, 0], degrees=True).as_matrix()\n",
    "del_t = np.array([0, 0, 0])\n",
    "del_extrinsic = [del_R, del_t]\n",
    "\n",
    "img_front.apply_extrinsic(del_extrinsic)\n",
    "\n",
    "# imshow(img_front.data['img'][..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(img_front, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data['intrinsic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (768, 256)\n",
    "intrinsic = [383.5, 127.5, 384, 384]\n",
    "\n",
    "img_front.apply_intrinsic(resolution=resolution, intrinsic=intrinsic)\n",
    "\n",
    "plt.imshow(img_front.data['img'][..., ::-1]); plt.show()\n",
    "plt.imshow(img_front.data['ego_mask']); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_mat = np.eye(3)\n",
    "flip_mat[1, 1] = -1\n",
    "\n",
    "img_front.flip_3d(flip_mat)\n",
    "\n",
    "imshow(img_front.data['img'][..., ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG MIRROR ROTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "R = Rotation.from_euler('xyz', [-90, 0, -90], degrees=True).as_matrix()\n",
    "Rx = Rotation.from_euler('x', -90, degrees=True).as_matrix()\n",
    "Ry = Rotation.from_euler('y', 0, degrees=True).as_matrix()\n",
    "Rz = Rotation.from_euler('z', -90, degrees=True).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "Rotation.from_euler('xyz', [0, 10, 90], degrees=True).as_euler('XYZ', degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, Rz @ Ry @ Rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ang_x, ang_y, ang_z = Rotation.from_matrix(R).as_euler('xyz', degrees=True)\n",
    "# print(ang_z)\n",
    "# ang_z_ = -180 - ang_z\n",
    "\n",
    "# R_ = Rotation.from_euler('xyz', [ang_x, ang_y, ang_z_], degrees=True).as_matrix()\n",
    "\n",
    "# print(np.round(R_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotation.from_euler('xyz', [180, 0, 0], degrees=True).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_mat = np.eye(3)\n",
    "# flip_mat[0, 0] = -1\n",
    "\n",
    "# flip_mat[0, 0] = -1\n",
    "flip_mat[1, 1] = -1\n",
    "# flip_mat[2, 2] = -1\n",
    "\n",
    "R = Rotation.from_euler('xyz', [-1, 2, 45], degrees=True).as_matrix()\n",
    "print(np.round(R, 3))\n",
    "# print(flip_mat)\n",
    "\n",
    "R_mirror = flip_mat.T @ R @ flip_mat\n",
    "\n",
    "print(np.round(R_mirror, 3))\n",
    "\n",
    "print(Rotation.from_matrix(R_mirror).as_euler('xyz', degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_mat.T @ flip_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(Rotation.from_euler('xyz', [-1, 2, 45], degrees=True).as_matrix(), 3), np.round(Rotation.from_euler('xyz', [1, 2, -45], degrees=True).as_matrix(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(Rotation.from_euler('xyz', [-90, 0, 135], degrees=True).as_matrix(), 3), np.round(Rotation.from_euler('xyz', [-90, 0, -225], degrees=True).as_matrix(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.uniform(0.9, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotation.from_euler('xyz', [-90, 0, 0], degrees=True).as_euler('xyz', degrees=True), Rotation.from_euler('xyz', [-90, 0, -180], degrees=True).as_euler('xyz', degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_camp.adjust_sharpness(sharpness=5)\n",
    "plt.imshow(cam_info['img'][..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_info['intrinsic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx, cy, fx, fy, *_ = cam_info['intrinsic']\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scene['frame_info'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen a Bbox3D transformable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box3d_rt_to_points(rt):\n",
    "    R, t, size = rt\n",
    "\n",
    "def box3d_points_to_rt(points):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = scene['frame_info']['1692759619664']['3d_boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data = boxes[0]\n",
    "box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_box3d = Bbox3D(box_data, {0: 'car', 1: 'pedestrian', 2: 'cyclist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_box3d.flip_3d(flip_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_box3d.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen a Polyline3D transformable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.transform import Polyline3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ids = list(scene['frame_info'].keys())\n",
    "\n",
    "polylines = scene['frame_info'][frame_ids[0]]['3d_polylines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in polylines:\n",
    "#     print(p['class'])\n",
    "polyline_data = polylines[3]\n",
    "polyline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3d_test = Polyline3D(polyline_data, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3d_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3d_test.flip_3d(flip_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3d_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, scope=\"item\"):\n",
    "        assert scope.lower() in [\"item\", \"batch\"]\n",
    "        self.scope = scope.lower()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "class RandomImageISP(Transform):\n",
    "    def __init__(self, *, \n",
    "                #  adjust_brightness={\"prob\": 0.5, \"range\": (0.5, 2.0)},\n",
    "                #  adjust_saturation={\"prob\": 0.5, \"range\": (0.0, 2.0)},\n",
    "                #  adjust_contrast={\"prob\": 0.5, \"range\": (0.5, 2.0)},\n",
    "                #  adjust_hue={\"prob\": 0.5, \"range\": (-0.5, 0.5)},\n",
    "                #  adjust_sharpness={\"prob\": 0.5, \"range\": (0.0, 2.0)},\n",
    "                #  posterize={\"prob\": 0.5, \"bits\": (4, 8)},\n",
    "                #  channel_shuffle={\"prob\": 0.5},\n",
    "                #  auto_contrast={\"prob\": 0.2},\n",
    "                 solarize={\"prob\": 1},\n",
    "                #  imequalize={\"prob\": 0.1},\n",
    "                 random_sequence=True,\n",
    "                 scope=\"item\",  **kwargs):\n",
    "        super().__init__(scope=scope)\n",
    "        transforms = list(inspect.signature(self.__init__).parameters.keys())[:-3]\n",
    "        self.random_sequence = random_sequence\n",
    "        self.sequence = []\n",
    "        for transform in transforms:\n",
    "            self.sequence.append({transform: eval(f\"{transform}\")})\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __call__(self, *transformables, **kwargs):\n",
    "        if self.random_sequence:\n",
    "            random.shuffle(self.sequence)\n",
    "        \n",
    "        sequence = {}\n",
    "        for transform in self.sequence:\n",
    "            sequence.update(transform)\n",
    "        \n",
    "        for transformable in transformables:\n",
    "            if transformable is not None:\n",
    "                for transform_func in sequence:\n",
    "                    print(transform_func)\n",
    "                    prob = sequence[transform_func]['prob']\n",
    "                    if random.random() < prob:\n",
    "                        if 'range' in sequence[transform_func]:\n",
    "                            random_value = random.uniform(*sequence[transform_func]['range'])\n",
    "                            getattr(transformable, transform_func)(random_value, **kwargs)\n",
    "                        elif 'bits' in sequence[transform_func]:\n",
    "                            random_value = random.randint(*sequence[transform_func]['bits'])\n",
    "                            getattr(transformable, transform_func)(random_value, **kwargs)\n",
    "                        else:\n",
    "                            getattr(transformable, transform_func)(**kwargs)\n",
    "        \n",
    "        return transformables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isp = RandomImageISP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isp(img_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_front.data['img'][..., ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen a OCCSDF Transformable\n",
    "\n",
    "- left 25.6m\n",
    "- right 25.6m\n",
    "- front 38.4m\n",
    "- bottom 12.8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_occ = np.zeros((5, 360, 120))\n",
    "H, W = test_occ.shape[1:]\n",
    "uu, vv = np.meshgrid(np.arange(W), np.arange(H))\n",
    "\n",
    "print(uu.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu, vv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Sequence Batch Group Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance([], (list, tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes['20230823_110018']['frame_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# from torch.utils.data import IterableDataset, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MvSequenceDataset:\n",
    "    def __init__(self, bucket_size=10, phase='train') -> None:\n",
    "        self.scenes = {'{:03d}'.format(g): ['{:05d}'.format(i) for i in range(50)] for g in range(10)}\n",
    "        self.bucket_size = bucket_size\n",
    "        assert phase in ['train', 'val', 'test']\n",
    "        self.phase = phase\n",
    "        if self.phase in ['train']:\n",
    "            self._sample_train_indices()\n",
    "        if self.phase in ['val', 'test']:\n",
    "            self._sample_test_indices()\n",
    "    \n",
    "    def __len__(self):\n",
    "        size = 0\n",
    "        for scene_id in self.scenes:\n",
    "            size += len(self.scenes[scene_id])\n",
    "        if self.phase in ['train']:\n",
    "            return size * self.bucket_size\n",
    "        if self.phase in ['val', 'test']:\n",
    "            return size\n",
    "    \n",
    "\n",
    "    def _sample_train_indices(self):\n",
    "        scenes = list(self.scenes.keys())\n",
    "        grouped_buckets = []\n",
    "        for scene_id in scenes:\n",
    "            buckets = []\n",
    "            for i in range(len(self.scenes[scene_id])):\n",
    "                i_start = i - self.bucket_size\n",
    "                bucket = []\n",
    "                for j in range(i_start, i):\n",
    "                    bucket.append('{}_{}'.format(scene_id, self.scenes[scene_id][max(0, j)]))\n",
    "                buckets.append(bucket)\n",
    "            random.shuffle(buckets)\n",
    "            grouped_buckets.extend(buckets)\n",
    "        random.shuffle(grouped_buckets)\n",
    "        self.grouped_buckets = grouped_buckets\n",
    "\n",
    "\n",
    "    def _sample_test_indices(self):\n",
    "        scenes = list(self.scenes.keys())\n",
    "        # random.shuffle(scenes)\n",
    "        grouped_buckets = []\n",
    "        for scene_id in scenes:\n",
    "            bucket = []\n",
    "            for frame_id in self.scenes[scene_id]:\n",
    "                bucket.append('{}_{}'.format(scene_id, frame_id))\n",
    "            grouped_buckets.append(bucket)\n",
    "        self.grouped_buckets = grouped_buckets\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            if self.phase in ['train']:\n",
    "                self._sample_train_indices()\n",
    "            if self.phase in ['val', 'test']:\n",
    "                self._sample_test_indices()\n",
    "            raise IndexError\n",
    "        group_index = index // self.bucket_size\n",
    "        bucket_index = index % self.bucket_size\n",
    "        return self.grouped_buckets[group_index][bucket_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MvGroupBacthSampler:\n",
    "\n",
    "    def __init__(self, group_sampler, batch_size, drop_last=True):\n",
    "        self.sampler = group_sampler\n",
    "        # batch_size better lower than len(self.sampler.grouped_buckets)\n",
    "        self.batch_size = batch_size\n",
    "        # self.buffer = []\n",
    "        # self.batch_buffer = [[] for _ in range(self.batch_size)]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler.grouped_buckets) * self.sampler.bucket_size // self.batch_size\n",
    "\n",
    "\n",
    "    # def __getitem__(self, batch_index):\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.sampler.grouped_buckets)\n",
    "        batched_group = [[], ] * self.batch_size\n",
    "        batch_index = 0\n",
    "        for group_id in range(len(self.sampler.grouped_buckets)):\n",
    "            batched_group[batch_index] = self.sampler.grouped_buckets[group_id]\n",
    "            batch_index += 1\n",
    "            if batch_index == self.batch_size:\n",
    "                for frame_id in range(self.sampler.bucket_size):\n",
    "                    batch = []\n",
    "                    for b in range(self.batch_size):\n",
    "                        batch.append(batched_group[b][frame_id])\n",
    "                    yield batch\n",
    "                batch_index = 0\n",
    "                batched_group = [[], ] * self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = MvSequenceDataset()\n",
    "bs = MvGroupBacthSampler(dd, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dd), len(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dd:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass\n",
    "\n",
    "class B(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(B(), B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_seed = 0\n",
    "random.seed('group_0')\n",
    "random.uniform(0, 1), random.uniform(0, 1), random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(['s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(population=['a', 'b', 'c'], weights=[0.1, 0.2, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = range(20)\n",
    "group_size=1\n",
    "frame_interval=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_interval = group_size * frame_interval\n",
    "# first_end_id = random.randint(frame_interval, group_interval)\n",
    "first_end_id = group_interval\n",
    "last_end_id = len(ll)\n",
    "\n",
    "end_inds = []\n",
    "\n",
    "for i in range(frame_interval):\n",
    "    first_id = first_end_id + i\n",
    "    end_inds.extend(ll[first_id::group_interval])\n",
    "\n",
    "end_inds = sorted(end_inds)\n",
    "\n",
    "if end_inds[-1] < last_end_id:\n",
    "    end_inds.append(last_end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for end_ind in end_inds:\n",
    "    index_list = list(range(end_ind - group_interval, end_ind)[::frame_interval])\n",
    "    print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from src.dataset.dataset import GroupBatchDataset\n",
    "from src.dataset.distributed import DistributedGroupSampler\n",
    "# from src.dataset.distributed import DistributedBatchSampler\n",
    "# from src.dataset.dataloader import EventDataLoader\n",
    "\n",
    "from src.dataset.transform import RandomImageISP, RandomRotationSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd = GroupBatchDataset(\n",
    "    name='MvParkingTest',\n",
    "    data_root=Path('../data/'),\n",
    "    info_path=Path('../data/20230823_110018/mv_4d_infos.pkl'),\n",
    "    dictionary={},\n",
    "    transformable_keys=[\n",
    "        'camera_images'\n",
    "    ],\n",
    "    transforms=[\n",
    "        # RandomImageISP(scope='batch'),\n",
    "        RandomRotationSpace(\n",
    "            prob=1.0,\n",
    "            angles=[0, 0, 10],\n",
    "            prob_inverse_cameras_rotation=1.0,\n",
    "            scope='group'\n",
    "        )\n",
    "    ],\n",
    "    phase='train',\n",
    "    batch_size=3,\n",
    "    group_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy(gbd) is gbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbd.groups), len(gbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692759858564, \n",
      "1692759858664, \n",
      "1692759858764, \n",
      "1692759858864, \n",
      "1692759858964, \n",
      "1692759859064, \n",
      "1692759859164, \n",
      "1692759859264, \n",
      "1692759859364, \n",
      "1692759859464, \n"
     ]
    }
   ],
   "source": [
    "group_batch = gbd[3]\n",
    "for frame_batch in group_batch:\n",
    "    for frame_dict in frame_batch:\n",
    "        print(frame_dict['frame_id'], end=', ')\n",
    "        # test_image = frame_dict['transformables']['camera_images'][0]\n",
    "        # plt.imshow(test_image.data['ego_mask']); plt.show()\n",
    "        # plt.title(frame_dict['frame_id'])\n",
    "        # plt.imshow(test_image.data['img'][..., ::-1]); plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = DistributedSampler(gbd, num_replicas=2, rank=0)\n",
    "s1 = DistributedSampler(gbd, num_replicas=2, rank=1)\n",
    "ss0 = DistributedGroupSampler(gbd, num_replicas=2, rank=0)\n",
    "ss1 = DistributedGroupSampler(gbd, num_replicas=2, rank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in ss0:\n",
    "#     print(ind)\n",
    "\n",
    "# for ind in ss1:\n",
    "#     print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a special collate function for the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_generator(batch):\n",
    "    return batch[0]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=gbd,\n",
    "    collate_fn=collate_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692759856664, 1692759850664, \n",
      "1692759856764, 1692759850764, \n",
      "1692759859264, 1692759849564, \n",
      "1692759859364, 1692759849664, \n",
      "1692759857664, 1692759855464, \n",
      "1692759857764, 1692759855564, \n",
      "1692759849864, 1692759850864, \n",
      "1692759849964, 1692759850964, \n",
      "1692759851064, 1692759850264, \n",
      "1692759851164, 1692759850364, \n",
      "1692759853064, 1692759849664, \n",
      "1692759853164, 1692759849764, \n"
     ]
    }
   ],
   "source": [
    "for ind, batch in enumerate(dataloader):\n",
    "    if ind > 5:\n",
    "        break\n",
    "    for frame_batch in batch:\n",
    "        for frame_dict in frame_batch:\n",
    "            print(frame_dict['frame_id'], end=', ')\n",
    "            # test_image = frame_dict['transformables']['camera_images'][0]\n",
    "            # plt.title(frame_dict['frame_id'])\n",
    "            # plt.imshow(test_image.data['img']); plt.show()\n",
    "        print()\n",
    "    # for frame_dict in batch:\n",
    "    #     print(frame_dict['frame_id'], end='; ')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, batch in enumerate(gbd):\n",
    "#     if ind > 5:\n",
    "#         break\n",
    "#     for frame_dict in batch:\n",
    "#         print(frame_dict['scene_id'], frame_dict['frame_id'], frame_dict['prev_exists'], end='; ')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0 = DistributedGroupSampler(gbd, num_replicas=2, rank=0)\n",
    "# s1 = DistributedGroupSampler(gbd, num_replicas=2, rank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0.rank_chunks[0][0], s1.rank_chunks[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0.dataset.cur_groups[0], s1.dataset.cur_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, batch in enumerate(s0):\n",
    "#     if ind > 5:\n",
    "#         break\n",
    "#     for frame_dict in batch:\n",
    "#         print(frame_dict['scene_id'], frame_dict['frame_id'], frame_dict['prev_exists'], end='; ')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, batch in enumerate(s1):\n",
    "#     if ind > 5:\n",
    "#         break\n",
    "#     for frame_dict in batch:\n",
    "#         print(frame_dict['scene_id'], frame_dict['frame_id'], frame_dict['prev_exists'], end='; ')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, (batch_0, batch_1) in enumerate(zip(s0, s1)):\n",
    "#     if ind > 5:\n",
    "#         break\n",
    "#     print('s0', end=': ')\n",
    "#     for frame_dict in batch_0:\n",
    "#         print(frame_dict['frame_id'], end=' ')\n",
    "#     print('s1', end=': ')\n",
    "#     for frame_dict in batch_1:\n",
    "#         print(frame_dict['frame_id'], end=' ')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = EventDataLoader(\n",
    "#     dataset=s0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader._dataset_kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, batch in enumerate(dataloader):\n",
    "#     if ind > 5:\n",
    "#         break\n",
    "#     for frame_dict in batch:\n",
    "#         print(frame_dict['scene_id'], frame_dict['frame_id'], frame_dict['prev_exists'], end='; ')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load PointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 'camera_images', 'lidar_points', \n",
    "    # 'camera_segs', 'camera_depths',\n",
    "    # 'bbox3d', 'square3d', 'cylinder3d', 'oriented_cylinder3d',\n",
    "    # 'polyline3d', 'polygon3d', 'parkingslot3d', 'trajectory',\n",
    "    # 'seg_bev', 'occ_sdf_bev', 'occ_sdf_3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
